{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score\n",
    "import fasttext\n",
    "import datetime\n",
    "import csv\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset and Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 dataset: IMDb, Rotten Tomato, Test dataset from Tieto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the IMDb dataset\n",
    "reviews_train = []\n",
    "for line in open('../data/movie_data/full_train.txt', 'r'):\n",
    "    \n",
    "    reviews_train.append(line.strip())\n",
    "    \n",
    "reviews_test = []\n",
    "for line in open('../data/movie_data/full_test.txt', 'r'):\n",
    "    \n",
    "    reviews_test.append(line.strip())\n",
    "    \n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test dataset from Tieto\n",
    "path = '../data/movie_review_data'\n",
    "classes = ['neg', 'pos']\n",
    "labels    = []\n",
    "test_data_mine = []\n",
    "space = ' '\n",
    "for j in range(len(classes)):\n",
    "  file_list = os.listdir(path+'/'+classes[j])\n",
    "  for i in file_list:\n",
    "    labels.append(j)\n",
    "    comment = open(path+'/'+classes[j]+'/'+i).read()\n",
    "    comment = comment.replace('\\n',' ')\n",
    "    test_data_mine.append(comment)\n",
    "# test_data = np.array(test_data)\n",
    "len(test_data_mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PhraseId  SentenceId                                             Phrase  \\\n",
      "0         1           1  A series of escapades demonstrating the adage ...   \n",
      "1         2           1  A series of escapades demonstrating the adage ...   \n",
      "2         3           1                                           A series   \n",
      "3         4           1                                                  A   \n",
      "4         5           1                                             series   \n",
      "5         6           1  of escapades demonstrating the adage that what...   \n",
      "6         7           1                                                 of   \n",
      "7         8           1  escapades demonstrating the adage that what is...   \n",
      "8         9           1                                          escapades   \n",
      "9        10           1  demonstrating the adage that what is good for ...   \n",
      "\n",
      "   Sentiment  \n",
      "0          1  \n",
      "1          2  \n",
      "2          2  \n",
      "3          2  \n",
      "4          2  \n",
      "5          2  \n",
      "6          2  \n",
      "7          2  \n",
      "8          2  \n",
      "9          2  \n"
     ]
    }
   ],
   "source": [
    "# Rotten Tomato Dataset, only training set has labels\n",
    "rotten_tomato_train = pd.read_csv('../data/rottenTomatoes/train.tsv', sep = '\\t')\n",
    "print(rotten_tomato_train.head(10))\n",
    "rotten_tomato_test  = pd.read_csv('../data/rottenTomatoes/test.tsv', sep = '\\t')\n",
    "rotten_tomato_train.drop_duplicates(subset = ['SentenceId'], keep='first', inplace = True)\n",
    "rotten_tomato_test.drop_duplicates(subset = ['SentenceId'], keep='first', inplace = True)\n",
    "rotten_tomato_train = rotten_tomato_train[~rotten_tomato_train['Sentiment'].isin([2])]\n",
    "rotten_tomato_train['Label'] = rotten_tomato_train['Sentiment'].apply(lambda x: 1 if x>2 else 0)\n",
    "rotten_tomato_train_x = list(rotten_tomato_train['Phrase'])\n",
    "rotten_tomato_train_y = list(rotten_tomato_train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing using regular expressions\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "# Replace the abbreviation with the complete words\n",
    "def _replacer(text):\n",
    "    replacement_patterns = [\n",
    "        (r'won\\'t', 'will not'),\n",
    "        (r'can\\'t', 'cannot'),\n",
    "        (r'i\\'m', 'i am'),\n",
    "        (r'ain\\'t', 'is not'),\n",
    "        (r'(\\w+)\\'ll', r'\\g<1> will'),\n",
    "        (r'(\\w+)n\\'t', r'\\g<1> not'),\n",
    "        (r'(\\w+)\\'ve', r'\\g<1> have'),\n",
    "        (r'(\\w+)\\'s', r'\\g<1> is'),\n",
    "        (r'(\\w+)\\'re', r'\\g<1> are'),\n",
    "        (r'(\\w+)\\'d', r'\\g<1> would')]\n",
    "    patterns = [(re.compile(regex), repl) for (regex, repl) in replacement_patterns]\n",
    "    s = text\n",
    "    for (pattern, repl) in patterns:\n",
    "        (s, _) = re.subn(pattern, repl, s)\n",
    "    return s\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    reviews = [_replacer(line) for line in reviews]\n",
    "    \n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)\n",
    "rotten_tomato_clean = preprocess_reviews(rotten_tomato_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/zhangjun/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_instance(row, label):\n",
    "    cur_row = []\n",
    "    #Prefix the index-ed label with __label__\n",
    "    label = \"__label__\" + str(label)  \n",
    "    cur_row.append(label)\n",
    "    cur_row.extend(nltk.word_tokenize(row.lower()))\n",
    "    return cur_row\n",
    "\n",
    "def preprocess_fasttext(input_file, labels, output_file):\n",
    "    i=0\n",
    "    with open(output_file, 'w') as csvoutfile:\n",
    "        csv_writer = csv.writer(csvoutfile, delimiter=' ', lineterminator='\\n')\n",
    "        for i in range(len(input_file)):\n",
    "            row_output = transform_instance(input_file[i],labels[i])\n",
    "            csv_writer.writerow(row_output )\n",
    "#             if i%10000 ==0:\n",
    "#                 print('index: {}'.format(i))\n",
    "#                 print(row_output)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    reviews_train_clean, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "preprocess_fasttext(X_train, y_train, '../data/fasttext/IMDb.train')\n",
    "preprocess_fasttext(X_val, y_val, '../data/fasttext/IMDb.val')\n",
    "preprocess_fasttext(reviews_test_clean, target, '../data/fasttext/IMDb.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-27 13:18:23.980914 START!\n",
      "Model trained with the hyperparameter \n",
      " {'lr': 0.1, 'epoch': 15, 'wordNgrams': 3, 'dim': 256}\n",
      "2020-01-27 13:18:45.366070Training complete.\n",
      "accuracy:0.9644266666666667,    validation:0.88528,    test:0.88508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyper_params = {\"lr\": 0.1,\n",
    "                \"epoch\": 15,\n",
    "                \"wordNgrams\": 3,\n",
    "                \"dim\": 256}     \n",
    "                               \n",
    "print(str(datetime.datetime.now()) + ' START!' )\n",
    "\n",
    "# Train the model.\n",
    "model = fasttext.train_supervised(input='../data/fasttext/IMDb.train', **hyper_params)\n",
    "print(\"Model trained with the hyperparameter \\n {}\".format(hyper_params))\n",
    "\n",
    "# CHECK PERFORMANCE\n",
    "print(str(datetime.datetime.now()) + 'Training complete.' )\n",
    "        \n",
    "result = model.test('../data/fasttext/IMDb.train')\n",
    "validation = model.test('../data/fasttext/IMDb.val')\n",
    "test = model.test('../data/fasttext/IMDb.test')\n",
    "        \n",
    "# DISPLAY ACCURACY OF TRAINED MODEL\n",
    "test_results = str(\"accuracy:\" + str(result[1])  + \",    validation:\" + str(validation[1]) + \",    test:\" + str(test[1])+ '\\n') \n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1999, 0.8664332166083042, 0.8664332166083042)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with Tieto Data\n",
    "test = preprocess_reviews(test_data_mine)\n",
    "preprocess_fasttext(test, labels, '../data/fasttext/tieto.test')\n",
    "model.test('../data/fasttext/tieto.test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this has to be the all time best computer animation classic even though most of the animations where experiments they have an artistic quality that has stood the test of time twelve years after it is release i have gone back to watch this video and found some inspiration for new types of computer graphics some of the techniques used in this video have never been full explored'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__label__1 this has to be the all time best computer animation classic even though most of the animations where experiments they have an artistic quality that has stood the test of time twelve years after it is release i have gone back to watch this video and found some inspiration for new types of computer graphics some of the techniques used in this video have never been full explored'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(transform_instance(X_train[0],target[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
